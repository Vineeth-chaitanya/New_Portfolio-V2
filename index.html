<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Vineeth Adapa | Data Scientist</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <!-- Hero section with ID -->
  <header id="hero">
    <h1>Vineeth Adapa</h1>
    <p><span class="accent">Data Scientist | ML Engineer</span></p>
  </header>

  <main>
    <section id="about">
      <p style="max-width: 600px;">I'm a data scientist who enjoys turning ideas into tools people actually rely on. Most of 
        my work sits at the overlap of Machine Learning, Statistics and Large Language Models. I enjoy
        taking messy, real world data and turning it into systems that help people make better decisions.
      </p>
      <p style="max-width: 600px;">
        Currently, At <span class="accent">Pan American Health Organization</span> I am spending most of my time working on Large Language Models to help 
        build recommendation systems. I try to be a perfectionist even with my data, thoughtful engineering, meaningful
        evaluation, and experiments that tell you something real.
      </p>
      <p style="max-width: 600px;">
        Before fully moving into data science, I worked as a data analyst, which taught me how
        data flows through Organizations and why clarity and reliability matter just as much as accuracy.
        That background paired with my master's degree in information sciences shapes how I work today.
        I write readable code, ask practical questions, and try to build systems others can understand and maintain.
      </p>
      <p style="max-width: 600px;">
        Most days, I'm running, playing volleyball or finding some excuse to get a workout in. Staying still 
        has never been my strong suit. 
      </p>
    </section>

    <section id="experience">
      <h2>Experience</h2>
      <div class="experience-item">
        <div class="date">Sep 2025 â€” Present</div>
        <h3>
          <a href="https://www.paho.org/en" target="_blank">Data Scientist Â· Pan American Health Organization</a>
        </h3>
        <p style="max-width: 620px;">At PAHO, I work across multilingual datasets and LLM-powered workflows to strengthen
          the journal's bibliometric and editorial intelligence. I design and operate LLM-powered
          NLP systems using models like Llama4:Scout and OpenAI text embedding models to classify
          research domains and generate article-similarity recommendations.
        </p>
        <p style="max-width: 620px;">
          A big part of my work is making these systems stable at scale token-aware batching,
          JSON repair, adaptive rate-limit handling and collaborating with editorial and bibliometric
          teams to unify datasets and support impact-factor initiatives.
        </p>
        <ul class="tech-list">
          <li>R programming</li>
          <li>Large-Language Models</li>
          <li>OpenAI text-embedding-3-large</li>
          <li>A/B testing</li>
        </ul>
      </div>

      <div class="experience-item">
        <div class="date">Feb 2025 â€” Sep 2025</div>
        <h3>
          <a href="https://www.uhc.com/" target="_blank">Data Scientist Â· United Health Group</a>
        </h3>
        <p style="max-width: 620px;">At UnitedHealth Group, I worked across large-scale claims, EHR, PBM,
          and eligibility datasets to strengthen population health analytics and risk-stratification workflows.
          I built and evaluated supervised ML models like XGBoost, Random Forest, and Logistics Regression to predict hospitalization
          risk, medication non-adherence, and emerging care gaps across diverse member populations.
        </p>
        <p style="max-width: 620px;">
          A major part of my work involved engineering clinically meaningful features such as comorbidity indices, utilization patterns,
          and adherence metrics (PDC/MPR), and operationalizing these models within HIPAA-aligned data pipelines. I collaborated closely with clinical,
          actuarial, and care-management teams to validate outputs, refine thresholds, and translate model insights into actionable
          dashboards that supported targeted interventions and improved care outcomes.
        </p>
        <ul class="tech-list">
          <li>Python</li>
          <li>SQL</li>
          <li>Logistic Regression</li>
          <li>XGBoost</li>
          <li>ROC-AUC</li>
          <li>HIPAA</li>
        </ul>
      </div>

      <div class="experience-item">
        <div class="date">Feb 2021 â€” Dec 2022</div>
        <h3>
          <a href="https://www.cognizant.com/us/en" target="_blank">Data Analyst Â· Cognizant Technology Solutions</a>
        </h3>
        <p style="max-width: 620px;">At Cognizant, I supported data ingestion, transformation, and validation workflows across
          SQL Server and Excel for financial services client. I optimized SQL queries, stored procedures,
          and reporting scripts to improve turnaround time and reliability. I also built Power BI
          dashboards that visualized KPIs and operational metrics, helping stakeholders make informed decisions.
        </p>
        <p style="max-width: 620px;">
          A lot of my work involved data-quality audits, root-cause analysis, and collaborating with
          cross-functional teams in Agile sprints to test and deploy analytics solutions into production.
        </p>
        <ul class="tech-list">
          <li>SQL Server</li>
          <li>Python</li>
          <li>Excel</li>
          <li>ETL workflows</li>
          <li>Power BI</li>
        </ul>
      </div>
    </section>

    <section id="projects">
      <h2>Projects</h2>
      <div class="project-grid">
        <div class="project-card">
          <a href="" target="_blank" class="project-link">
            <span class="link-icon">ðŸ”—</span>
          </a>
          <h3>Causal Policy Optimization for Vaccine Allocation
            <span class="neo-dot-pulse" title="Actively working"></span>
          </h3>
          <p style="max-width: 620px;">
            This Project replicates California state's real world vaccine rollout dynamics by generating a synthetic population with 
            age, comorbidities, exposure risk, and socioeconomic factors reflective of the state's demographics. Using a biased,
            historically inspired logging policy, where high-risk groups were vaccinated earlier, I recreated the confounding patterns
            seen in California's observational data. On top of this simulated environment, we evaluate and optimize new vaccine allocation strategies
            using Causal off-policy methods, quantifying uncertainity through confidence intervals and regret analysis.
          </p>
          <ul class="tech-list">
            <li>Causal Inference</li>
            <li>Statistical Modeling</li>
            <li>Inverse Propensity Weighting</li>
            <li>Doubly Robust Estimation</li>
          </ul>

        </div>
        <div class="project-card">
            <a href="https://github.com/Vineeth-chaitanya/USBondYield_Prediction" target="_blank" class="project-link">
                <span class="link-icon">ðŸ”—</span>
            </a>
            <h3>US Bond Yield Forecasting</h3>
            <p style="max-width: 620px;">I developed a forecasting system for US 10-year Treasury bond yields using macroeconomic indicators.
                The project compared ARIMAX, LSTMs, and attention-based neural networks to capture long-term trends
                and improve predictive accuracy. It highlights my ability to blend statistical modeling with modern deep 
                learning for financial time-series analysis.
            </p>
            <ul class="tech-list">
                <li>Python</li>
                <li>Pandas</li>
                <li>scikit-learn</li>
                <li>ARIMAX</li>
                <li>LSTM</li>
            </ul>
        </div>
        
        <div class="project-card">
            <a href="https://github.com/Vineeth-chaitanya/AQI-Prediction" target="_blank" class="project-link">
                <span class="link-icon">ðŸ”—</span>
            </a>
            <h3>AQI Prediction</h3>
            <p style="max-width: 620px;">
                I built a machine learning pipeline to predict Air Quality Index(AQI) levels using meterological
                and pollutant data. The project involved cleaning and engineering features from raw environmental
                datasets, then experimenting with regression models and ensemble methods to forecast AQI with higher accuracy.
                I emphasized evaluation metrics like RMSE and RÂ² to validate performance, and visualized predictions
                against actual AQI trends to ensure the system provided actionable insights.
            </p>
            <ul class="tech-list">
                <li>R</li>
                <li>XGBoost</li>
                <li>Random Forest</li>
                <li>shiny</li>
            </ul>

        </div>
        <div class="project-card">
            <a href="https://github.com/Vineeth-chaitanya/Resume_analyser" target="_blank" class="project-link">
                <span class="link-icon">ðŸ”—</span>
            </a>
            <h3>Resume Analyzer</h3>
            <p style="max-width: 620px;">
                I built a resume parsing system that processes unstructured text from resumes and converts it into structured, recruiterâ€‘friendly data. 
                Using spaCy NLP pipelines, the system extracts key fields such as skills, education, and work experience, then standardizes them into consistent formats for easier screening. 
                The project was tested on over 2,500 resumes, demonstrating its ability to automate manual review and reduce recruiter workload. Beyond extraction, 
                I focused on clean data engineering and validation, ensuring outputs were reliable enough to integrate into downstream HR workflows
            </p>
            <ul class="tech-list">
                <li>Python</li>
                <li>spaCy</li>
                <li>Regex</li>
                <li>NLP</li>
            </ul>

        </div>
      </div>
    </section>
  </main>

<aside class="social-sidebar horizontal">
  <div class="sidebar-line"></div> <!-- Thin line above icons -->
  <ul>
    <li>
      <a href="https://github.com/Vineeth-chaitanya" target="_blank" aria-label="GitHub">
        <img src="github.svg" alt="GitHub">
      </a>
    </li>
    <li>
      <a href="https://www.linkedin.com/in/vineeth-chaitanya-1914101b5/" target="_blank" aria-label="LinkedIn">
        <img src="linkedin.svg" alt="LinkedIn">
      </a>
    </li>
    <li>
      <a href="mailto:vineethadapa01@gmail.com" aria-label="Email">
        <img src="email.svg" alt="Email">
      </a>
    </li>
  </ul>
</aside>

<footer id="contact">  
  <p class="footer-credit">Â© 2025 Vineeth Adapa</p>
</footer>


  <!-- JavaScript at the end of body -->
  <script src="script.js"></script>
</body>
</html>